{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Semantic A-Roll/B-Roll Engine - Google Colab Backend\n",
    "\n",
    "**Problem:** Local Windows system crashes with PyTorch  \n",
    "**Solution:** Run backend on Colab's free GPU!\n",
    "\n",
    "## Setup (Run these cells in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install -q fastapi uvicorn pydantic python-multipart\n",
    "!pip install -q google-cloud-aiplatform\n",
    "!pip install -q faiss-cpu numpy pillow\n",
    "!pip install -q torch torchaudio\n",
    "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
    "!apt-get install -qq ffmpeg\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 2: Clone your code (or upload files)\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Option A: Upload your backend folder as ZIP\n",
    "print(\"Upload your 'backend' folder as a .zip file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "!unzip -q backend.zip\n",
    "print(\"‚úÖ Backend code uploaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 3: Setup GCP credentials\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GCP_PROJECT_ID'] = 'firstproject-c5ac2'\n",
    "os.environ['GCP_LOCATION'] = 'us-central1'\n",
    "os.environ['WHISPER_DEVICE'] = 'cuda'  # Use Colab's GPU!\n",
    "os.environ['CUDA_DEVICE'] = 'cuda'\n",
    "\n",
    "print(\"‚úÖ GCP authenticated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 4: Create directories\n",
    "!mkdir -p uploads outputs data models/whisperx\n",
    "print(\"‚úÖ Directories created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 5: Install ngrok to expose API\n",
    "!pip install -q pyngrok\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Get your ngrok authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "ngrok.set_auth_token(\"YOUR_NGROK_TOKEN_HERE\")  # ‚Üê Replace this!\n",
    "\n",
    "print(\"‚úÖ Ngrok configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 6: Start FastAPI backend\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Start uvicorn in background thread\n",
    "def run_server():\n",
    "    uvicorn.run(\n",
    "        \"backend.main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "import time\n",
    "time.sleep(5)  # Wait for server to start\n",
    "\n",
    "print(\"‚úÖ FastAPI server started!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 7: Expose with ngrok\n",
    "public_url = ngrok.connect(8000)\n",
    "\n",
    "print(f\"\\nüåê Your public API URL:\")\n",
    "print(f\"   {public_url}\")\n",
    "print(f\"\\nüìù Copy this URL and use it in your local Streamlit frontend!\")\n",
    "print(f\"\\n   Change API_BASE in frontend/app.py to:\")\n",
    "print(f\"   API_BASE = '{public_url}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 8: Test with JSON\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Your video JSON\n",
    "video_json = {\n",
    "    \"a_roll\": {\n",
    "        \"url\": \"https://fzuudapb1wvjxbrr.public.blob.vercel-storage.com/food_quality_ugc/a_roll.mp4\",\n",
    "        \"metadata\": \"Food quality awareness\"\n",
    "    },\n",
    "    \"b_rolls\": [\n",
    "        {\n",
    "            \"id\": \"broll_1\",\n",
    "            \"url\": \"https://fzuudapb1wvjxbrr.public.blob.vercel-storage.com/food_quality_ugc/broll_1.mp4\",\n",
    "            \"metadata\": \"Mumbai street food\"\n",
    "        }\n",
    "        # Add all 6 B-Rolls here...\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send to backend\n",
    "response = requests.post(\n",
    "    f\"{public_url}/api/process/json\",\n",
    "    json=video_json\n",
    ")\n",
    "\n",
    "job_id = response.json()['job_id']\n",
    "print(f\"‚úÖ Processing started! Job ID: {job_id}\")\n",
    "\n",
    "# Monitor status\n",
    "while True:\n",
    "    status = requests.get(f\"{public_url}/api/status/{job_id}\").json()\n",
    "    print(f\"Status: {status['status']} - {status['progress']}% - {status['message']}\")\n",
    "    \n",
    "    if status['status'] in ['complete', 'error']:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "if status['status'] == 'complete':\n",
    "    print(\"\\nüéâ Processing complete!\")\n",
    "    print(f\"   Download: {public_url}/api/download/{job_id}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Error: {status.get('error', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Session Alive\n",
    "\n",
    "Run this cell to prevent Colab from disconnecting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Keep alive script\n",
    "import time\n",
    "while True:\n",
    "    print(\"‚úÖ Backend running...\", end='\\r')\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
